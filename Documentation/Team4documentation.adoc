# Pronunciation Coach - Project Documentation

**INSO4101: Introduction to Software Engineering**
**Team 4**
**September 19, 2025**

---

##1. Informative Part
###1.1 Team:
Joy Martinez | Team Leader:
- Led project coordination and research
- Researched about randomization in multiple choice quizzes
- Worked on a feature to verify a input word's validation

Yediel J Acosta | Developer:
- Researched about Text to IPA translators
- Worked on a Speech to Text translator (by dependencies)
- Documented Team 4's Milestone 1
- Participating in the presentation of Team 4's Milestone 1

Adriel Bracero | Developer:
- Researched about the following topics:
  > Stress Placement and Basic Word Intonation
  > On-Device Pitch Extraction & Normalization
  > Noise Robustness and Preprocessing

Diego | Developer:
- Researched for implementing Slow-Motion audios for Pronunciation Practice

Iralys Sanchez | Developer:
- Researched about the following topics:
  > Validation of Spoken Word Input
  > Methods for Building Quiz Word/Question Bank

###1.2 Current Situation, Needs, and Ideas:
####1.2.1 Current Situation:
- English language is important to learn, but Pronunciation practice has obstacles:
  > Lack of Immediate Feedback
  > Traditional Class Focusing on Writing & Reading Practice
  > Tutors' high entrance cost
  > App's absence of broad Pronunciation Practice
- Mentioned Issues decrease Students' motivation
- Lacking motivation leads to Inconsistent Practice & Failure

####1.2.2 Needs:
- App focused on English Speech Practice
- Said App Needs to Cultivate Motivation & Learning Discipline

####1.2.3 Ideas:
- "Pronunciation Coach" Project that will Develop a Plataform for English Speech Education
- App allows Speech Practice and Construct Discipline

###1.3 Scope & Span:
####1.3.1 Scope:
- Develop Disciplinary App to Practice English Speech
- Target Audience: Persons Interested in Individual Coaching
- "Pronunciation Coach" App Requirements:
  > Internet Accessibility
  > Minimally Noisy Environment
  > Mobile App / Web Browser
- Development Completed by end of November 2025

####1.3.2 Span:
- Time Frame: 4 months and 3 weeks, end of November 2025
- Front End: Flutter & Dart
- Back End: Python
- Architecture: Client-Server

###1.4 Synopsis:
- English Pronunciation Practice has numerous Obstacles
- Obstacles deter Students' motivation, which deter Practice and Leads to Failure
- Need for App focused on English Speech Practice that Motivates Students to Learn
- "Pronunciation Coach" Project will develop a Speech Practice App
- "Pronunciation Coach" App:
  > Test English Speech & Constructs Discipline
  > Targets Students interested in Individual Coaching
  > Requires Internet Access, Minimally Noisy Environment, and Mobile App / Web Browser
  > Flutter & Dart Front End, Python Back End with Client-Based Architecture
  > Development finishes by end of November 2025

###1.6 Other Activities:
- Multiple Research on topics that can be Implemented in the "Pronunciation Coach" App as the Domain allows it
- Discuss adjacent topics that allow for a Domain Expansion once Main Objectives are Completed
- Test Various Features to Confirm Efficiency

###1.7 Derived Goals:
- Save a Student's previous Exercises to Determine Scores
- Implement IPA Definitions to Contextualize Information
- Offer Speech Graphs that Determine pronunciation Information

##2. Descriptive Part
###2.1 Domain Description:
####2.1.1 Domain Rough Sketch:
- LEARNING USER represents User with interest of learning English Speech
- PRONUNCIATION EDUCATION APPLICATION is the set of entities, behaviors, functions, etc. such:
  > Educates Users of English Speech
- SPEECH is verbal communication done in the App
  > English subset
- PHONETIC SYMBOLS are the IPA Symbols that represent sounds
  > English subset
- TRANSLATOR is the core function that allows conversion of the following inputs:
  > English words
  > English IPA Symbols
  > Speech audio

####2.1.2 Terminology:
- "Pronunciation Coach" Application:
  > Set of entities, behaviors, functions, etc. such that allow English Speech Education
- Student:
  > User of the App with the Interest of Studying & Learning English Speech
- Speech:
  > Verbal communication done through the App, English subset
- IPA:
  > International Phonetic Alphabet Symbols that represent sound, English subset
- Translator:
  > Functions that allow English words, IPA symbols, or speech to be converted to other symbols

####2.1.3 Domain Terminology VS Rough Sketch:
Format:
- Rough Sketch Definition:
  > Interpretation
  > Terminology

- Learning User:
  > Represents Character with Conversation Education Interest
  > Student
- Pronunciation Education Application:
  > Entities, Behaviors, etc. used to Instruct Conversational English
  > Pronunciation Coach Application
- Speech:
  > Verbal English Communication through App
  > Speech
- Phonetic Symbols:
  > Letters that define English sounds by text
  > IPA
- [...] Translator:
  > Function that Converts between English words/IPA/audio
  > Translator

####2.1.4 Domain Narrative:
- Assume Arbitrary number of Students:
  > Subset1 of Students Request IPA
    * App returns IPA Documentation
    * App returns IPA Pronunciation
  > Subset2 of Students Test Speech:
    * App Translates Speech to Text/Graphs
    * App Determines Pronunciation Accuracy
  > Subset3 of Students Test IPA:
    * App Returns IPA Symbols
    * App Expects Students' Conversion to Text

####2.1.5 Events, Actions, and Behaviors:
- Events:
  > IPA Documentation has been Presented
  > Speech has been Translated to Text
  > Student Speech has been Graphed
- Actions:
  > IPA Definition:
    * Students want IPA Context:
      # IPA Context was Requested
    * Accept Request:
      # Return IPA Documentation
      # IPA Documentation was Presented

####2.1.6 Function Signatures:
- Save Speech:
  > Speech: Audio --> Text --> List<Text>
- Profile Creation:
  > Profile: Email * Password --> User

####2.1.7 Phenomena and Concepts for Quiz Feature:

- This section distinguishes between the phenomena and concepts within the quiz feature.
- Phenomena are observable, concrete instances that occur during execution
(ex. the word displayed, user inputs, printed options, and quiz results).
- Concepts are abstractions that represent a set of related phenomena, 
such as the entities, functions, and behaviors.

- Phenomena (examples observed at runtime):
  > Displayed words such as "destiny", "thou", "bass", or "coke".
  > The IPA transcription strings retrieved from the JSON file (ex. "ˈdɛstɪni").
  > The number of syllables shown for each word.
  > The four printed answer options (one correct, three distractors) visible to the user.
  > The user’s input (ex. Answer: 2) and whether it is correct or incorrect.
  > Console outputs such as "Correct!", "Incorrect!", or "Select a valid answer!".
  > The running result summary (ex. "Number of Correct Answers: 3/4").
  > Audio output played by TTS_Speak(option).

- Concepts
  > Entities (concepts that carry data):
    - Word: lexical item selected for the quiz.
    - IPA: phonetic transcription retrieved through Get_Word_IPA(word).
    - Syllables: number of syllables retrieved through Get_Word_Syllables(word).
    - WordEntry: composed data structure (Word, IPA, Syllables).
    - OptionSet: shuffled list of four possible answers generated by Generate_Evil_Words(word).
    - QuizState: stores quiz progress (num_quizes, num_incorrect, continue_quiz, is_correct).
  
  > Functions (operations that act on entities):
    - Select_Word(word_list) -> Word - selects a random word from the list.
    - Get_Word_IPA(word) -> IPA - retrieves the word’s IPA transcription.
    - Get_Word_Syllables(word) -> Syllables - retrieves syllable count.
    - Generate_Evil_Words(word) -> OptionSet - generates three distractors and the correct option.
    - TTS_Speak(option) -> AudioOutput - reads each option aloud during the quiz.

  > Events & Behaviors (dynamic flow):
    - WordRequested: system selects a new Word.
    - OptionsGenerated: distractors created and shuffled.
    - OptionSelected: user selects an option (1–4).
    - AnswerChecked(correct/incorrect): result determined
    - ContinueChosen(y/n): user chooses whether to continue or exit.
    - QuizEnded: session finishes and results displayed.

  > Invariants / Constraints:
    - OptionSet always contains exactly four items with only one correct answer.
    - All options must be different.
    - Quiz continues until all words are answered correctly or the user exits.

###2.2 Requirements:
####2.2.1 User Stories, Epics, Features:
- As a forgein Student, I want to be able to know if I'm speaking correctly, so that I can spot my errors & work in fixing them.
- As a begginer Student, I want the IPA symbols' pronunciations so that I can practice English sounds I struggle with.
- As a curious Student, I want to be told my mistakes so that I can work on fixing them.

####2.2.2 Personas:
- Students with strong accent who wants to pronounce American English sounds properly
- Students who struggle in relating to known phonetic in new words:
  > Ex. Knowing "come", but not "become"
- Students who know English, but struggle communicating
- English mayor Students who want to learn the IPA

####2.2.3 Domain Requirements:
- System must store Students' profiles
- System must offer IPA context
- System must foment Activate practice
- System must correct unproper speech
- System must test Students' performance

####2.2.4 Interface Requirements:
- System must scale for any device
- System must display speech activities
- System must show correct profiles
- System must have legible Information
- System must allow account creation

####2.3.5 Machine Requirements:
- System must support 500+ Students
- System must load lessons by 0.5 seconds
- System must retrieve profiles by 0,4 seconds
- System must run on phones or desktops
- System must avoid 10GB+ space consumption

###2.3 Implementation
####2.3.1 Selected Fragment of Implementation:
- [Snippet] Speech to Text Translator: Microphone audio --> Text
  void _listen() async {
    if (!_isHearing) {
      setState(() => _text = "Listening...");
      _speech.listen(
        onResult:(result) {
          setState(() {
            _text = result.recognizedWords;
            _confidence = result.confidence;
          });
        },
      );
      setState(() => _isHearing = true);
    } else {
      _speech.stop();
      setState(() => _isHearing = false,);
      saveResult(_text);
      setState(() => _text = "Press the button and speak");
    }
  } 

##3. Analytic Part:
###3.1 Concept Analysis:
- Student is abstraction of User with Speech interest
- Speech is an abstraction of Conversational English
- IPA is an abstraction for English Symbols of International Phonetic Alphabet
- Translator is an abstract of a function that converts inputs to English words/IPA/audio

###3.2 Validation and Verification:
- Validation will be constant, with higher emphasis by Milestone Stamps
  > Moderators that run quality-control:
    * Professor
    * Managers
    * Team Leaders
    * Team Members
- Verification will run by Developers during Implementations
  > Example of Forms of Verification:
    * Unit Testing
    * Model-Checking

####3.2.1 Validation Scenarios:

- Validation complements verification by confirming that the system being developed 
is the one stakeholders actually want. “Are we doing the right thing?”
- Each scenario below represents a concrete, inspectable situation that a stakeholder 
could review without any technical knowledge.

> Scenario A – Pronunciation Feedback

  - Goal: Allow learners to confirm whether their spoken words are correctly pronounced.
  - Stakeholder Perspective: I want immediate, understandable feedback on pronunciation quality.
  
  - Preconditions:
    > Student is logged into the app.
    > Microphone permission granted.
    > Audio output device available.
  
  - Main Flow:
    > Student chooses to practice their pronunciation.
    > Select the words they want to practice.
    > Press record and pronounce the first word.
    > App analyzes audio -> converts speech to text -> computes pronunciation score.
    > Screen shows pronunciation score and highlighted problematic sounds, as well as feedback.
    > Process repeats until all words have been practiced.
  
  - Edge Cases:
    > Background noise detected 
      -> App pauses and displays “Detecting a lot of background noise,
      please move to a quieter area.”
    > No speech captured 
      -> Prompt to re-record.
    > Spoken input ambiguous (ex. “wood” vs. “would”) 
      -> App pauses and displays “Your pronunciation matches several words. Please confirm which one you meant.” 
      Then shows a small list of candidate words for student to choose. Student selects intended word, 
      program continues. If none match, then student is prompted the option to try again.
                  
  - Observable Outcomes:
    > Score displayed per word.
    > Mispronounced syllables highlighted.
    > Feedback tip (ex. “/æ/ sounds too short”).
  
  - Acceptance Criteria:
    > Given clear input audio, when the learner records a word, 
    the app displays the score and some feedback tips within 2-3 seconds.
    > Given background noise above the defined threshold, when recording starts, 
    the app shows the noisy environment warning and prevents scoring.

> Scenario B – Custom Quiz Practice

  - Goal: Let a learner practice self-chosen words via 4-option 
  IPA questions (with audio for each option), receive immediate correctness feedback, 
  and then speak the word through STT for pronunciation feedback.
  - Stakeholder Perspective: I want to practice my words, hear how each IPA option sounds, 
  choose the right one, and then try saying it to get feedback.

  - Preconditions:
    > Student is logged into the app.
    > Microphone permission granted.
    > Audio output device available.
    > Cached audio present.
  
  - Main Flow:
    > Student selects Quiz -> Custom Practice.
    > App prompts “How many words do you want to practice?” Student enters a number N (ex. 5).
    > App prompts the student to input N words. (ex. software, computer, friend, thought, joy).
    > For each word, the app generates one 4-option question: each option is an IPA rendering of the 
    target word (one correct and three distractors).
    > Student can tap a speaker icon on each option to hear that IPA realized as audio.
    > Student chooses an option -> App shows correct/incorrect with feedback tip(s).
    > After answering all questions, App prompts the student to "say the word" for each practiced word.
    > Student records pronunciation -> App analyzes and shows feedback per-word, 
    which includes the score and feedback tip(s).
    > App displays a results page with: overall quiz score, per-word question results,
    and per-word speaking score. Student can choose to retry or save their results to their profile.
  
  - Edge Cases:
    > User enters a number N ≤ 0 or non-integer: 
      -> App prompts “Please enter a whole number greater or equal to 1”.
    > A typed input word is not recognized (OOV): 
      -> App suggests closest matches or asks the student to replace the word.
    > An audio option fails to play: 
      -> App shows “Playback error” and offers re-fetch. Question can still be answered.
    > A duplicate word is entered: 
      -> App prompts the student to “Please enter a different word”.

  - Observable Outcomes:
    > Running list of all entered words remains visible until quiz starts.
    > A clear progress indicator during the IPA questions and the speaking step.
    > Each item shows 4 options, each with a speaker icon. The selected option is visually marked.
    > Immediate Correct/Incorrect marker plus at least one feedback tip.
    > Final results page with overall % score, per-word IPA question results, and per-word speaking score.
    > If saved, a new history entry appears with timestamp, quiz information, and scores.

  - Acceptance Criteria:
    > Given a number N ≥ 1 and N words entered: when the quiz starts, exactly N items are presented, 
    each with 4 options and audio playback per option.
    > Given a valid item, when the learner taps an option, 
    the App shows Correct/Incorrect and at least one feedback tip within 2-3 seconds.
    > Given the speaking step, when the student records a word, 
    the App returns a pronunciation score percentage and at least one feedback tip within 2-3 seconds.
    > Given a playback error during audio fetch, 
    the App shows “Playback error-Audio unavailable” and still allows a selection.

####3.2.2 Verification Plan for Quiz:

- Verification confirms that the implementation is correct by proving the quiz behaves as required 
under normal and abnormal conditions. “Are we doing it right?”

- This plan covers the complete quiz flow, including:
  > Custom word entry
  > 4-option IPA questions with audio 
  > Correctness feedback
  > Spoken pronunciation step
  > Results saving and history

- Methods utilized:
  > Unit Testing
  > Property-Based Testing
  > Integration/UI Testing
  > Contract Testing
  > Negative/Robustness Testing

- Requirements list:
  > R1: Options cardinality and correctness (4 options, 1 correct, all different).
  > R2: Randomized correct option placement across attempts.
  > R3: Audio playback available with fallback on error.
  > R4: Microphone permission required before speaking step.
  > R5: Speaking feedback timing (score + tip <= 3 seconds).
  > R6: Save results and show history within <= 5 seconds.
  > R7: Input validation for invalid, duplicate, or OOV words.
  > R8: Robustness during network or playback failures.

- Verification Cases:
  > Case 1 – Options Distinctiveness and Single Correct Answer
    - Requirement(s): R1
    - Preconditions: word = “software.”
    - Steps: Generate the options with the word (“software”).
    - Expected Output: Exactly 4 options; all distinct; one marked as correct.
    
  > Case 2 – Randomized Correct Option Position
    - Requirement(s): R2
    - Preconditions: word = “computer.”
    - Steps: Run 100 quiz generations with random values.
    - Expected Output: Correct option varies across positions; not fixed in one slot.

  > Case 3 – Audio Playback Success
    - Requirement(s): R3
    - Preconditions: Audio output enabled.
    - Steps: Tap each speaker icon.
    - Expected Output: Audio plays successfully; selection remains enabled.

  > Case 4 – Audio Playback Failure Fallback
    - Requirement(s): R3, R8
    - Preconditions: Triggered audio fetch error.
    - Steps: Tap speaker icon.
    - Expected Output: “Playback error” displayed; question can still be answered.

  > Case 5 – Microphone Permission Gating
    - Requirement(s): R4
    - Preconditions: Mic permission not granted.
    - Steps: Enter spoken pronunciation step.
    - Expected Output: App prompts “Enable microphone to continue”; recording disabled until granted.

  > Case 6 – Speaking Feedback Timing
    - Requirement(s): R5
    - Preconditions: Mic permission granted.
    - Steps: Record and submit pronunciation.
    - Expected Output: Score and feedback tip(s) displayed within 2–3 seconds.

  > Case 7 – Save Results and Idempotence
    - Requirement(s): R6
    - Preconditions: Quiz completed; network available.
    - Steps: Save results twice.
    - Expected Output: One entry appears in history; no duplicates created.

  > Case 8 – Input Validation (Invalid N)
    - Requirement(s): R7
    - Preconditions: N = 0 or non-integer value.
    - Steps: Attempt to start quiz.
    - Expected Output: App shows “Please enter a whole number greater or equal to 1.”
 
  > Case 9 – Duplicate or OOV Words
    - Requirement(s): R7
    - Preconditions: User enters duplicates or unrecognized words.
    - Steps: Start quiz.
    - Expected Output: Duplicates removed; OOV prompts replacement.

  > Case 10 – Network Loss During Audio Fetch
    - Requirement(s): R8
    - Preconditions: Network temporarily unavailable.
    - Steps: Play word audio.
    - Expected Output: Fallback message displayed; quiz continues normally.

- Performance Checks:
  > Question generation time <= 3 seconds.
  > Speaking feedback (score + tip(s)) <= 3 seconds.
  > Results saved and visible in history <= 5 seconds, 
  or flagged as “Pending Sync” if offline.